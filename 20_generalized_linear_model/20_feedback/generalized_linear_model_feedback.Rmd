---
title: "20 Generalized linear model"
author: "Tobias Gerstenberg"
date: "3/1/2019"
output: 
  html_document:
    toc: true
    toc_depth: 4
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
library("knitr")
library("DT")
library("tidyverse")
opts_chunk$set(echo = TRUE)
theme_set(
  theme_classic() + 
    theme(
      text = element_text(size = 20),
      panel.grid.major.y = element_line(color = "gray90")
    ) 
)
```

> The lecture is pretty clear in illustrating the concepts of lmer models. But I think, in the future, you may want to make use of some mathematical equations to clearly illustrate how the model can remove "random intercept", "correlations between random effects" and etc. This is because I still find it difficult to wrap my head around for all these concepts by simply looking at the lmer model syntax, instead of the read equations. Thanks!

> Really liked the class. I thought the visualizations of the tumor data were super helpful.

> Might have been helpful to explain what "converging" meant before explaining what to do about it. Otherwise, this was great!

## Student feedback 

```{r echo=FALSE, message=FALSE}
read_csv("what-did-you-like-about-20.csv") %>% 
  set_names(c("response", "date")) %>% 
  select(response) %>% 
  datatable()
```

### PollEverywhere results 

```{r echo=FALSE, message=FALSE, results='hide'}
df.pace = read.csv("how-was-the-pace-of-20.csv", header = F) %>%
  filter(row_number() > which(.$V2 == "Created At")) %>% 
  set_names(c("response", "date")) %>% 
  mutate(response = factor(response, levels = c("much too slow", "a little too slow", "just right", "a little too fast", "much too fast"),
                           labels = c("much\ntoo slow", "a little\ntoo slow", "just right", "a little\ntoo fast", "much\ntoo fast"))) %>% 
  count(response) %>% 
  complete(response, fill = list(n = 0))

ggplot(data = df.pace,
       mapping = aes(x = response, y = n)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") +
  scale_y_continuous(breaks = seq(0, 30, 2), labels = seq(0, 30, 2)) + 
  labs(y = "number of students", x = "", title = "How was the pace of today's class?")
# ggsave("pace.pdf", width = 8, height = 6)
```

```{r echo=FALSE, message=FALSE, results='hide'}
df.overall = read_csv("how-happy-were-you-with-20.csv") %>% 
  set_names(c("response", "date")) %>% 
  filter(!str_detect(response, "Click")) %>% # remove response outside of the click regions 
  mutate(response = as.numeric(response),
         response = factor(response, levels = 1:5,
                           labels = c("very\nunhappy", "unhappy", "neutral", "happy", "very\nhappy"))) %>% 
  count(response) %>% 
  complete(response, fill = list(n = 0))

ggplot(data = df.overall,
       mapping = aes(x = response, y = n)) + 
  geom_bar(stat = "identity", aes(fill = response), color = "black", show.legend = F) +
  scale_fill_manual(values = c("red", "orange", "yellow", "lightgreen", "green")) +
  labs(y = "number of students", x = "", title = "How happy were you with today's class overall?") +
  scale_y_continuous(breaks = seq(0, 30, 2), labels = seq(0, 30, 2)) + 
  theme(title = element_text(size = 18))
# ggsave("overall.pdf", width = 8, height = 6)
```

## Homework 5 

```{r echo=FALSE, message=FALSE, results='hide'}
df.hw5_hours = read.csv("how-many-hours-hw5.csv", header = F) %>%
  filter(row_number() > which(.$V2 == "Created At")) %>% 
  set_names(c("response", "date")) %>% 
  mutate(response = factor(response,
                           levels = c(1:14, "15+"))) %>% 
  count(response) %>% 
  complete(response, fill = list(n = 0))

ggplot(data = df.hw5_hours,
       mapping = aes(x = response, y = n)) + 
  geom_bar(stat = "identity", fill = "lightblue", color = "black") +
  labs(y = "number of students", x = "", title = "How many hours did you spend on hw5?")
# ggsave("hw5_hours.pdf", width = 8, height = 6)
```

## What to do next time

- make sure to explain what "converging" means before talking about what to do about it if the model doesn't converge 
- the explanation of nested vs. crossed models can be improved 
- figure out whether it's possible to have interactions in the random effects structure 
- the Titanic data set is good for illustrating logistic regression 
- the visualization demo at the beginning helped 
- maybe: talk a little more about how to interpret odds 
- managed to get until slide 63 (before "Fitting and reporting models")

