---
title: "Things that came up in class"
author: "Tobias Gerstenberg"
output:
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    theme: cosmo
    highlight: tango
bibliography: [references.bib]
---

# Load packages 

```{r}
library("knitr")      # for knitting 
library("pwr")        # for power analysis
library("effectsize") # for effect sizes
library("broom")      # for tidying up model fits
library("ggsignif")   # for showing significant differences in plots
library("kableExtra") # for nice tables
library("corrr")      # for correlation tables
library("lme4")       # for linear mixed effects models 
library("MASS")       # for additional function (e.g. multivariate Gaussian)
library("janitor")    # for cleaning column names
library("tidyverse")  # for everything else 

theme_set(theme_classic() + #set the theme 
            theme(text = element_text(size = 20))) #set the default text size

opts_chunk$set(comment = "",
               fig.show = "hold")

options(dplyr.summarise.inform = F)
```

# degrees of freedom 

t-distributions with different degrees of freedom 

```{r}
ggplot(data = tibble(x = c(-5, 5)),
       mapping = aes(x = x)) +
  stat_function(fun = ~ dt(., df = 100),
                color = "black",
                size = 1) + 
  stat_function(fun = ~ dt(., df = 5),
                color = "red",
                size = 1)
```

# t-test vs. permutation test 

**Question**: Why should we ever run a t-test instead of a permutation test? 

**Some considerations**: 

- running a t-test is fast, whereas running a permutation test can take some time 
- if the assumptions for a t-test are met (normally distributed residuals, homogeneity of variance), there is little benefit to running a permutation test
- if the assumptions aren't met (e.g. heavy tails of the residual distribution), permutation test may have more power (it is more robust to the test assumptions being violated)

Let's take a look at how a t-test and a permutation test compare in terms of power

## define the true population 

```{r}
n = 20
mean1 = 10
sd1 = 10 
mean2 = 12
sd2 = 10 

# population 
df.population = tibble(group_1 = rnorm(n = n,
                                       mean = mean1,
                                       sd = sd1),
                       group_2 = rnorm(n = n,
                                       mean = mean2, 
                                       sd = sd2)) %>% 
  pivot_longer(cols = everything())

# parameters
df.params = df.population %>% 
  group_by(name) %>% 
  summarize(mean = mean(value),
            sd = sd(value))
```

significance test 

```{r}
lm(formula = value ~ name,
   data = df.population) %>% 
  summary()
```

### power calculation using `pwr`

```{r}
d = cohens_d(x = value ~ name,
             data = df.population)

pwr.t.test(d = d,
           power = 0.8,
           sig.level = 0.05)
```

### power via simulation 

#### using a t-test 

```{r}
# make reproducible 
set.seed(1)

# parameters 
mean1 = df.params$mean[1]
mean2 = df.params$mean[2]
sd1 = df.params$sd[1]
sd2 = df.params$sd[2]

# number of simulations
n_simulations = 50

# run simulation 
df.power = crossing(n = seq(10, 60, 2),
                    simulation = 1:n_simulations) %>%
  mutate(index = 1:n()) %>% 
  group_by(index, n, simulation) %>% 
  mutate(data = list(tibble(group1 = rnorm(n = n,
                                           mean = mean1,
                                           sd = sd1),
                            group2 = rnorm(n = n,
                                           mean = mean2,
                                           sd = sd2)) %>% 
                       pivot_longer(cols = everything()))) %>% 
  group_by(index, n, simulation) %>% 
  mutate(fit = map(data, 
                   ~ t.test(formula = value ~ name,
                            data = .x))) %>% 
  mutate(coef = map(fit, tidy)) %>% 
  select(simulation, n, index, coef) %>% 
  unnest(cols = coef) %>% 
  group_by(n) %>% 
  summarize(power = sum(p.value < 0.05) / n())

# visualize results
ggplot(data = df.power, 
       mapping = aes(x = n,
                     y = power)) +
  geom_hline(yintercept = seq(0, 1, 0.1),
             linetype = 2,
             color = "gray50",
             size = 0.1) + 
  geom_smooth(method = "loess",
              color = "black") +
  geom_point(shape = 21)
```

#### using a permutation test 

I've set the code chunk to `eval=F` because this takes a relatively long time to run. 

```{r, eval=F}
# make reproducible 
set.seed(1)

# parameters 
mean1 = df.params$mean[1]
mean2 = df.params$mean[2]
sd1 = df.params$sd[1]
sd2 = df.params$sd[2]

difference = abs(mean1 - mean2)

# number of simulations
n_simulations = 10

# number of permutations 
n_permutations = 20

# permutation test 
func_permutations = function(df, n_permutations, difference){
  map_lgl(1:n_permutations, 
          ~ df %>%
            mutate(name = sample(name)) %>% # random shuffle
            group_by(name) %>%
            summarize(mean = mean(value)) %>%
            pull(mean) %>%
            diff() %>% 
            abs() >= difference) %>% 
    sum()
}

# run simulation 
df.power2 = crossing(n = seq(10, 60, 2),
                     simulation = 1:n_simulations) %>%
  mutate(index = 1:n()) %>% 
  group_by(index, n, simulation) %>% 
  mutate(data = list(tibble(group1 = rnorm(n = n,
                                           mean = mean1,
                                           sd = sd1),
                            group2 = rnorm(n = n,
                                           mean = mean2,
                                           sd = sd2)) %>% 
                       pivot_longer(cols = everything()))) %>% 
  group_by(index, n, simulation) %>% 
  mutate(p.value = map_dbl(data, ~ func_permutations(df = .,
                                                     n_permutations = n_permutations,
                                                     difference = difference)),
         p.value = p.value/n_permutations) %>% 
  group_by(n) %>% 
  summarize(power = sum(p.value < 0.05) / n())

# visualize results
ggplot(data = df.power2, 
       mapping = aes(x = n,
                     y = power)) +
  geom_hline(yintercept = seq(0, 1, 0.1),
             linetype = 2,
             color = "gray50",
             size = 0.1) + 
  geom_smooth(method = "loess",
              color = "black") +
  geom_point(shape = 21)
```

# difference in significance vs. significant differences 

```{r}
set.seed(2) # make reproducible
n = 10
mean1 = 0
sd1 = 0.3
mean2 = 0.5
sd2 = 0.4
mean3 = 0.2
sd3 = 0.4

# simulate data 
df.difference = tibble(placebo = rnorm(n = n,
                                       mean = mean1,
                                       sd = sd1),
                       group_1 = rnorm(n = n,
                                       mean = mean2, 
                                       sd = sd2),
                       group_2 = rnorm(n = n,
                                       mean = mean3,
                                       sd = sd3)) %>% 
  pivot_longer(cols = everything(),
               names_to = "group",
               values_to = "outcome") %>% 
  mutate(group = factor(group, levels = c("placebo", "group_1", "group_2")))

# visualize results 
ggplot(data = df.difference,
       mapping = aes(x = group,
                     y = outcome)) +
  stat_summary(fun.data = "mean_cl_normal") + 
  geom_signif(comparisons = list(c("placebo", "group_1")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1) + 
  geom_signif(comparisons = list(c("placebo", "group_2")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1.4) + 
  geom_signif(comparisons = list(c("group_1", "group_2")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1.2) + 
  scale_x_discrete(labels = c("Placebo", "Treatment A", "Treatment B")) +
  coord_cartesian(ylim = c(-0.2, 1.5))

# placebo vs. group_1
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("placebo", "group_1")))

# placebo vs. group_2
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("placebo", "group_2")))

# group_1 vs. group_2
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("group_1", "group_2")))
```

# when to standardize predictors 

## correlations between continuous predictors 

```{r}
set.seed(1)

x1 = rnorm(100, 10, 1)
x2 = rnorm(100, 15, 1) 
x1x2 = x1*x2
x1c = x1 - mean(x1)
x2c = x2 - mean(x2)
x1x2c = x1c * x2c
df.data = tibble(x1, x2, x1x2, x1c, x2c, x1x2c)


df.data %>% 
  correlate() %>% 
  shave() %>% 
  fashion()
```

```{r}
set.seed(1)

x1 = 1:10
x2 = rnorm(10) 
x1x2 = x1*x2
x1c = x1 - mean(x1)
x2c = x2 - mean(x2)
x1x2c = x1c * x2c
df.data = tibble(x1, x2, x1x2, x1c, x2c, x1x2c)

df.data %>% 
  correlate() %>% 
  shave() %>% 
  fashion()
```

## read in data set 

```{r}
df.poker = read_csv("data/poker.csv") %>% 
  # mutate(skill = 3 - skill,
  mutate(skill_fct = factor(skill,
                        # levels = 1:2,
                        levels = 2:1,
                        labels = c("average", "expert")),
         hand_fct = factor(hand,
                       levels = 1:3,
                       labels = c("bad", "neutral", "good")),
         skill_z = scale(skill),
         hand_z = scale(hand),
         skill_c = scale(skill, scale = F),
         hand_c = scale(hand, scale = F))
```

## visualize results 

```{r}
df.plot = df.poker

p = ggplot(data = df.plot,
       mapping = aes(x = hand_fct,
                     y = balance,
                     group = skill_fct,
                     color = skill_fct,
                     fill = skill_fct)) + 
  geom_point(alpha = 0.2,
             position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.1),
             show.legend = F) + 
  stat_summary(fun.data = "mean_cl_boot",
               position = position_dodge(width = 0.5),
               size = 1,
               color = "black",
               shape = 21) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "hand",
       fill = "skill") +
  theme(legend.position = "bottom")
p 
```

## data table 

```{r}
df.poker %>% 
  select(hand, skill, hand_fct, skill_fct, balance) %>% 
  sample_n(7) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## continuous predictors (not normalized)

```{r}
# with continuous predictor 
fit1 = lm(formula = balance ~ 1 + hand + skill, 
   data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand * skill, 
   data = df.poker)
summary(fit2)
```

## correlations between predictors 

```{r}
df.poker %>% 
  select(hand, skill, balance) %>% 
  mutate(hand_x_skill = hand * skill) %>% 
  select(hand, skill, hand_x_skill, balance) %>% 
  sample_n(4) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```


```{r}
df.poker %>% 
  mutate(hand_x_skill = hand * skill) %>% 
  select(hand, skill, hand_x_skill, balance) %>% 
  correlate() %>% 
  shave() %>% 
  fashion() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## with continuous predictors (centered)

```{r}
fit1 = lm(formula = balance ~ 1 + hand_c + skill_c, 
   data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_c * skill_c, 
   data = df.poker)
summary(fit2)
```

```{r}
df.poker %>% 
  mutate(hand_x_skill_c = hand_c * skill_c) %>% 
  select(hand_c, skill_c, hand_x_skill_c, balance) %>% 
  correlate() %>% 
  shave() %>% 
  fashion() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```



# dummy-coding vs. effect coding 

## model fits 

```{r}
# df.poker = df.poker %>% 
#   mutate(hand = hand_fct)

fit1 = lm(formula = balance ~ 1 + hand, 
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand, 
          contrasts = list(hand = "contr.sum"),
          data = df.poker)
summary(fit2)
```

## coefficients

```{r}
# dummy coded 
fit1 %>% 
  tidy() %>% 
  select(term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)

# effect coded 
fit2 %>% 
  tidy() %>% 
  select(term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```


## model matrix: dummy coding

```{r}
model.matrix( ~ hand, 
              data = df.poker %>% 
                distinct(hand),
              contrasts = list(hand = "contr.treatment")) %>% 
  as_tibble() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## model matrix: effect coding

```{r}
model.matrix( ~ hand, 
              data = df.poker %>% 
                distinct(hand),
              contrasts = list(hand = "contr.sum")) %>% 
  as_tibble() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

```{r}
df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = round(mean(balance), 2)) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## categorical predictors (effect-coded)

```{r}
fit1 = lm(formula = balance ~ 1 + skill_fct,
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + skill_fct, 
          contrasts = list(skill_fct = "contr.sum"),
          data = df.poker)
summary(fit2)

contr.sum(2)
contr.treatment(2)
```

```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct,
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_fct, 
          contrasts = list(hand_fct = "contr.sum"),
          data = df.poker)
summary(fit2)

model.matrix( ~ hand_fct, 
              data = df.poker %>% 
                distinct(hand_fct),
              contrasts = list(hand_fct = "contr.sum"))
```

```{r}
model.matrix( ~ hand_fct + skill_fct, 
              data = df.poker %>% 
                distinct(hand_fct, skill_fct),
              contrasts = list(hand_fct = "contr.sum",
                               skill_fct = "contr.sum"))
```

```{r}
9.7715 - 3.8300
9.7715 + 0.5751
9.7715 + (-3.8300) * -1 + 0.5751 * -1
```


```{r}
df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))
```

```{r}
params = fit2 %>% 
  tidy() %>% 
  pull(estimate)

params[1] + (1) * params[2] + (0) * params[3]
params[1] + (0) * params[2] + (1) * params[3]
params[1] + (-1) * params[2] + (-1) * params[3]
```

```{r}
group_means = df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))

(group_means$mean[3] - group_means$mean[1]) / 2
```




```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct + skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_fct * skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)
summary(fit2)
```

```{r}
df.poker %>% 
  group_by(hand, skill) %>% 
  summarize(mean = mean(balance))
```



```{r}
# df.model = fit1 %>%
df.model = fit2 %>%
  augment() %>% 
  distinct(hand_fct, skill_fct, balance = .fitted)
  
p + 
  geom_point(data = df.model,
             color = "black",
             position = position_dodge(width = 0.5),
             size = 3)
```


- Given the dummy coding, the intercept represents the mean for `hand = bad` in the model without the interaction, but it represents the mean for `hand = bad, skill = average` in the model with the intercept 

```{r}
df.poker %>% 
  group_by(hand, skill) %>% 
  summarize(mean = mean(balance))

df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))

df.poker %>% 
  group_by(skill) %>% 
  summarize(mean = mean(balance))

# 10.1 - 9.4
```


- Note: The outcome here should not be interpreted to mean that the quality of the hand makes no difference. 
- these are not main effects but simple effects 

```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct * skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)

fit2 = lm(formula = balance ~ 1 + hand_fct * skill_fct,
          data = df.poker)

```

# centering with multiple continuous predictors 

```{r}
df.tmp = tibble(hand = rep(1:3, 2),
                skill = rep(1:2, each = 3),
                hand_skill = hand * skill,
                hand_c = scale(hand, scale = F),
                skill_c = scale(skill, scale = F),
                hand_skill_c = hand_c * skill_c)

df.tmp %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
                full_width = F)

df.tmp %>% 
  cor()
```

# using a pilot to determine sample size 

```{r}
set.seed(1)
population.sd = 5
sample_n = 100
pilot_n = 10 
n_pilots = 10000

sample_sd = rnorm(n = sample_n, sd = population.sd) %>% 
  sd()

df.plot = tibble(sd = map_dbl(1:n_pilots, ~ rnorm(n = pilot_n, sd = population.sd) %>% 
  sd()))

ggplot(df.plot,
       aes(x = sd)) + 
  geom_histogram(color = "black",
                 fill = "lightblue") + 
  geom_vline(xintercept = 5,
             linetype = 2) + 
  geom_vline(xintercept = mean(df.plot$sd),
             color = "red")

```


# Comparing t-test with F-test in `lm()`

What's the difference between the t-test on individual predictors in the model and the F-test comparing two models (one with, and one without the predictor)? 

Let's generate some data first: 

```{r lmer1-1}
# make example reproducible 
set.seed(1)

# parameters
sample_size = 100
b0 = 1
b1 = 0.5
b2 = 0.5
sd = 0.5

# sample
df.data = tibble(
  participant = 1:sample_size,
  x1 = runif(sample_size, min = 0, max = 1),
  x2 = runif(sample_size, min = 0, max = 1),
  # simple additive model
  y = b0 + b1 * x1 + b2 * x2 + rnorm(sample_size, sd = sd) 
) 

# fit linear model 
fit = lm(formula = y ~ 1 + x1 + x2,
         data = df.data)

# print model summary 
fit %>% summary()
```

Let's visualize the data: 

```{r lmer1-2}
df.data %>% 
  ggplot(data = .,
         mapping = aes(x = x1,
                       y = y,
                       color = x2)) +
  geom_smooth(method = "lm",
              color = "black") + 
  geom_point()
```

## Global F-test 

The global F-test which is shown by the F-statistic at the bottom of the `summary()` output compares the full model with a  model that only has an intercept. So, to use our model comparison approach, we would compare the following two models: 

```{r lmer1-3}
# fit models 
model_compact = lm(formula = y ~ 1,
                   data = df.data)

model_augmented = lm(formula = y ~ 1 + x1 + x2,
                     data = df.data)

# compare models using the F-test
anova(model_compact, model_augmented)

```

Note how the result of the F-test using the `anova()` function which compares the two models is identical to the F-statistic reported at the end of the `summary` function.

## Test for individual predictors

To test for individual predictors in the model, we compare two models, a compact model without that predictor, and an augmented model with that predictor. Let's test the significance of `x1`. 

```{r lmer1-4}
# fit models 
model_compact = lm(formula = y ~ 1 + x2,
                   data = df.data)

model_augmented = lm(formula = y ~ 1 + x1 + x2,
                     data = df.data)

# compare models using the F-test
anova(model_compact, model_augmented)
```

Note how the p-value that we get from the F-test is equivalent to the one that we get from the t-test reported in the `summary()` function. The F-test statistic (in the `anova()` result) and the t-value (in the `summary()` of the linear model) are deterministically related. In fact, the relationship is just: 

$$
t = \sqrt{F}
$$

Let's check that that's correct: 

```{r lmer1-5, warning=FALSE}
# get the t-value from the fitted lm
t_value = fit %>% 
  tidy() %>% 
  filter(term == "x1") %>% 
  pull(statistic)

# get the F-value from comparing the compact model (without x1) with the 
# augmented model (with x1)

f_value = anova(model_compact, model_augmented) %>% 
  tidy() %>% 
  pull(statistic) %>% 
  .[2]

# t-value 
print(str_c("t_value: ", t_value))

# square root of f_value 
print(str_c("sqrt of f_value: ", sqrt(f_value)))
```

Yip, they are the same. 

# Difference between `replicate()` and `map()`

`replicate()` comes with base R whereas `map()` is part of the tidyverse. `map()` can do everything that `replicate()` can do and more. However, if you just want to run the same function (without changing the parameters) multiple times, you might as well use `replicate()`. 

Here are some examples for what you can do with `replicate()` and `map()`.

```{r lmer2-1}
# draw from a normal distribution and take mean
fun.normal_means = function(n, mean, sd){
  mean(rnorm(n = n, mean = mean, sd = sd))
}

# execute the function 4 times
replicate(n = 4, fun.normal_means(n = 20, mean = 1, sd = 0.5))

# same same but different 
map_dbl(.x = c(20, 20, 20, 20), ~ fun.normal_means(n = .x, mean = 1, sd = 0.5))

# and more flexible
map_dbl(.x = c(1, 1, 10, 10), ~ fun.normal_means(n = 20, mean = .x, sd = 0.5))
```

# One-tailed vs. two-tailed tests

## t distribution

Some code to draw a t-distribution: 

```{r}
tibble(x = c(-4, 4)) %>% 
  ggplot(data = ., 
         mapping = aes(x = x)) + 
  stat_function(fun = "dt",
                args = list(df = 20),
                size = 1,
                geom = "area",
                fill = "red",
                # xlim = c(qt(0.95, df = 20), qt(0.999, df = 20))) +
                # xlim = c(qt(0.001, df = 20), qt(0.05, df = 20))) +
                xlim = c(qt(0.001, df = 20), qt(0.025, df = 20))) +
  stat_function(fun = "dt",
                args = list(df = 20),
                size = 1,
                geom = "area",
                fill = "red",
                xlim = c(qt(0.975, df = 20), qt(0.999, df = 20))) +
  stat_function(fun = "dt",
                args = list(df = 20),
                size = 1) +
  coord_cartesian(expand = F)
```

## F distribution

Some code to draw an F-distribution

```{r}
tibble(x = c(0, 5)) %>% 
  ggplot(data = ., 
         mapping = aes(x = x)) +
  stat_function(fun = "df",
                args = list(df1 = 100, df2 = 10),
                size = 1,
                geom = "area",
                fill = "red",
                xlim = c(qf(0.95, df1 = 100, df2 = 10), qf(0.999, df1 = 100, df2 = 10))) +
  stat_function(fun = "df",
                args = list(df1 = 100, df2 = 10),
                size = 1) +
  coord_cartesian(expand = F)
```


## Multivariate Gaussians 

```{r}
sigma = matrix(data = c(1, -0.5, 0, 1),
               nrow = 2,
               ncol = 2)

mvrnorm(n = 10000,
        mu = rep(0, 2),
        Sigma = sigma) %>% 
  as_tibble(.name_repair = ~ set_names(c("x", "y"))) %>% 
  ggplot(mapping = aes(x = x,
                       y = y)) + 
  stat_density_2d(aes(fill = stat(level)),
                  geom = "polygon",
                  show.legend = F)
```

## `ggtext()`

```{r}

n = 100

df.plot = tibble(x = rep(1, n),
                 y = rep(1, n),
                 text = "test")

ggplot(data = df.plot,
       mapping = aes(x = x,
                     y = y)) + 
  geom_text(aes(label = text),
            size = 10)
  # annotate(geom = "text",
  #          x = 1, 
  #          y = 1,
  #          label = "test",
  #          size = 10)
```

```{r}
df.plot = tibble(x = c(1, 2),
                 y = c(1, 2),
                 panel = c("A", "B"),
                 text = c("test1", "test2"))

ggplot(data = df.plot,
       mapping = aes(x = x,
                     y = y)) + 
  geom_text(aes(label = text),
            size = 10) + 
  facet_grid(cols = vars(panel)) + 
  coord_cartesian(xlim = c(0.5, 2.5),
                  ylim = c(0.5, 2.5))

df.plot %>% 
  kable() %>% 
  kable_styling()
```

# Bias in Cosyne 2019 conference admission? 

Code up the data: 

```{r bda1-1}
# data frame 
df.conference = tibble(sex = rep(c("female", "male"), c(264, 677)),
  accepted = rep(c("yes", "no", "yes", "no"), c(83, 264 - 83, 255, 677 - 255))) %>%
  mutate(accepted = factor(accepted, levels = c("no", "yes"), labels = 0:1),
    sex = as.factor(sex))
```

Visualize the results: 

```{r bda1-2}
df.conference %>% 
  ggplot(data = .,
         mapping = aes(x = sex, fill = accepted)) + 
  geom_bar(color = "black") + 
  scale_fill_brewer(palette = "Set1") +
  coord_flip() +
  theme(legend.direction = "horizontal",
        legend.position = "top") + 
  guides(fill = guide_legend(reverse = T))
```

Run a logistic regression with one binary predictor (Binomial test):

```{r bda1-3}
# logistic regression
fit.glm = glm(formula = accepted ~ 1 + sex,
              family = "binomial",
              data = df.conference)

# model summary 
fit.glm %>% 
  summary()
```

The results of the logistic regression are not quite significant (at least when considering a two-tailed test) with $p = .0741$. 

Let's run a permutation test (as suggested by the tweet I showed in class):

```{r bda1-4, cache=TRUE}
# make example reproducible 
set.seed(1)

# difference in proportion 
fun.difference = function(df){
  df %>% 
    as_tibble() %>% 
    count(sex, accepted) %>% 
    group_by(sex) %>% 
    mutate(proportion = n / sum(n)) %>% 
    filter(accepted == 1) %>% 
    select(sex, proportion) %>% 
    spread(sex, proportion) %>% 
    mutate(difference = male - female) %>% 
    pull(difference)  
}

# actual difference 
difference = df.conference %>% 
  fun.difference()

# permutation test 
df.permutation = df.conference %>% 
  permute(n = 1000, sex) %>% 
  mutate(difference = map_dbl(perm, ~ fun.difference(.)))
```

Let's calculate the p-value based on the permutation test: 

```{r bda1-5}
sum(df.permutation$difference > difference) / nrow(df.permutation)
```

And let's visualize the result (showing our observed value and comparing it to the sampling distribution under the null hypothesis):  

```{r bda1-6}
df.permutation %>% 
  ggplot(data = .,
         mapping = aes(x = difference)) +
  stat_density(geom = "line") + 
  geom_vline(xintercept = difference, 
             color = "red",
              size = 1)
```

# normally distributed dv vs. residuals 

```{r}
set.seed(1)
n = 50
reference = 1 
difference = 10 
sd = 2

# create data 
df.data = tibble(participant = 1:(n*2),
                 condition = rep(0:1, each = n),
                 response = reference + condition * difference + rnorm(n = n*2, sd = sd)) %>% 
  mutate(condition = condition + 1,
         condition = as.factor(condition))

# plot the data 
ggplot(data = df.data,
       mapping = aes(x = condition,
                     y = response)) + 
  geom_point(position = position_jitter(width = 0, height = 0),
             alpha = 0.1) + 
  stat_summary(fun.data = "mean_cl_boot",
               shape = 21, 
               fill = "lightblue",
               size = 1)

# test for normality of the dependent variable 
shapiro.test(df.data$response)

# fit a normal distribution to the data 
fit_normal_dv = fitdistr(df.data$response, densfun = "normal")

# plot dependent variable and normal distribution 
ggplot(data = df.data,
       mapping = aes(x = response)) + 
  geom_density(bw = 1) + 
  stat_function(fun = ~dnorm(x = .,
                             mean = fit_normal_dv$estimate[1],
                             sd = fit_normal_dv$estimate[2]),
                color = "red",
                size = 1) +
  stat_function(fun = ~dnorm(x = .,
                             mean = reference,
                             sd = sd)/2,
                color = "blue",
                linetype = 2,
                size = 1) + 
  stat_function(fun = ~dnorm(x = .,
                             mean = reference + difference,
                             sd = sd)/2,
                color = "blue",
                linetype = 2,
                size = 1)

# fit the model to the data 
fit_model = lm(formula = response ~ 1 + condition,
               data = df.data)

df.fit = fit_model %>% 
  augment() %>% 
  clean_names()

# fit a normal distribution to the residuals 
fit_normal_residuals = fitdistr(df.fit$resid, densfun = "normal")

# plot residual and normal distribution 
ggplot(data = df.fit,
       mapping = aes(x = resid)) + 
  geom_density(bw = 1) + 
  stat_function(fun = ~dnorm(x = .,
                             mean = fit_normal_residuals$estimate[1],
                             sd = fit_normal_residuals$estimate[2]),
                color = "red",
                size = 1)
```

# density and cumulative probability distribution for unifrom distribution

```{r}
ggplot(data = tibble(x = c(0, 0.2)),
       mapping = aes(x = x)) + 
  stat_function(fun = ~ dunif(., min = 0, max = 0.2)) + 
  coord_cartesian(expand = F)

ggplot(data = tibble(x = c(0, 0.2)),
       mapping = aes(x = x)) + 
  stat_function(fun = ~ punif(., min = 0, max = 0.2)) + 
  coord_cartesian(expand = F)
```

# F-distributions with different parameters 

```{r}
pc = 1
pa = 2
n = 20

ggplot(data = tibble(x = c(0, 10)),
       mapping = aes(x = x)) + 
  stat_function(fun = ~ df(., df1 = pa-pc, df2 = n-pa)) +
  scale_y_continuous(limits = c(0, 1.5))

pc = 1
pa = 8
n = 20

ggplot(data = tibble(x = c(0, 10)),
       mapping = aes(x = x)) + 
  stat_function(fun = ~ df(., df1 = pa-pc, df2 = n-pa)) +
  scale_y_continuous(limits = c(0, 1.5))

```

