---
title: "Things that came up in class"
author: "Tobias Gerstenberg"
output:
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    theme: cosmo
    highlight: tango
bibliography: [references.bib]
---

```{r setup, include=FALSE}
# these options here change the formatting of how comments are rendered
knitr::opts_chunk$set(comment = "#>",
                      fig.show = "hold")
```

# Load packages 

```{r}
library("knitr")      # for knitting 
library("pwr")        # for power analysis
library("effectsize") # for effect sizes
library("broom")      # for tidying up model fits
library("ggsignif")   # for showing significant differences in plots
library("kableExtra") # for nice tables
library("corrr")      # for correlation tables
library("tidyverse")  # for everything else 

theme_set(theme_classic() + #set the theme 
            theme(text = element_text(size = 20))) #set the default text size
```

# degrees of freedom 

t-distributions with different degrees of freedom 

```{r}
ggplot(data = tibble(x = c(-5, 5)),
       mapping = aes(x = x)) +
  stat_function(fun = ~ dt(., df = 100),
                color = "black",
                size = 1) + 
  stat_function(fun = ~ dt(., df = 5),
                color = "red",
                size = 1)
```

# t-test vs. permutation test 

**Question**: Why should we ever run a t-test instead of a permutation test? 

**Some considerations**: 

- running a t-test is fast, whereas running a permutation test can take some time 
- if the assumptions for a t-test are met (normally distributed residuals, homogeneity of variance), there is little benefit to running a permutation test
- if the assumptions aren't met (e.g. heavy tails of the residual distribution), permutation test may have more power (it is more robust to the test assumptions being violated)

Let's take a look at how a t-test and a permutation test compare in terms of power

## define the true population 

```{r}
n = 20
mean1 = 10
sd1 = 10 
mean2 = 12
sd2 = 10 

# population 
df.population = tibble(group_1 = rnorm(n = n,
                                       mean = mean1,
                                       sd = sd1),
                       group_2 = rnorm(n = n,
                                       mean = mean2, 
                                       sd = sd2)) %>% 
  pivot_longer(cols = everything())

# parameters
df.params = df.population %>% 
  group_by(name) %>% 
  summarize(mean = mean(value),
            sd = sd(value))
```

significance test 

```{r}
lm(formula = value ~ name,
   data = df.population) %>% 
  summary()
```

### power calculation using `pwr`

```{r}
d = cohens_d(x = value ~ name,
             data = df.population)

pwr.t.test(d = d,
           power = 0.8,
           sig.level = 0.05)
```

### power via simulation 

#### using a t-test 

```{r}
# make reproducible 
set.seed(1)

# parameters 
mean1 = df.params$mean[1]
mean2 = df.params$mean[2]
sd1 = df.params$sd[1]
sd2 = df.params$sd[2]

# number of simulations
n_simulations = 50

# run simulation 
df.power = crossing(n = seq(10, 60, 2),
                    simulation = 1:n_simulations) %>%
  mutate(index = 1:n()) %>% 
  group_by(index, n, simulation) %>% 
  mutate(data = list(tibble(group1 = rnorm(n = n,
                                           mean = mean1,
                                           sd = sd1),
                            group2 = rnorm(n = n,
                                           mean = mean2,
                                           sd = sd2)) %>% 
                       pivot_longer(cols = everything()))) %>% 
  group_by(index, n, simulation) %>% 
  mutate(fit = map(data, 
                   ~ t.test(formula = value ~ name,
                            data = .x))) %>% 
  mutate(coef = map(fit, tidy)) %>% 
  select(simulation, n, index, coef) %>% 
  unnest(cols = coef) %>% 
  group_by(n) %>% 
  summarize(power = sum(p.value < 0.05) / n())

# visualize results
ggplot(data = df.power, 
       mapping = aes(x = n,
                     y = power)) +
  geom_hline(yintercept = seq(0, 1, 0.1),
             linetype = 2,
             color = "gray50",
             size = 0.1) + 
  geom_smooth(method = "loess",
              color = "black") +
  geom_point(shape = 21)
```

#### using a permutation test 

I've set the code chunk to `eval=F` because this takes a relatively long time to run. 

```{r, eval=F}
# make reproducible 
set.seed(1)

# parameters 
mean1 = df.params$mean[1]
mean2 = df.params$mean[2]
sd1 = df.params$sd[1]
sd2 = df.params$sd[2]

difference = abs(mean1 - mean2)

# number of simulations
n_simulations = 10

# number of permutations 
n_permutations = 20

# permutation test 
func_permutations = function(df, n_permutations, difference){
  map_lgl(1:n_permutations, 
          ~ df %>%
            mutate(name = sample(name)) %>% # random shuffle
            group_by(name) %>%
            summarize(mean = mean(value)) %>%
            pull(mean) %>%
            diff() %>% 
            abs() >= difference) %>% 
    sum()
}

# run simulation 
df.power2 = crossing(n = seq(10, 60, 2),
                     simulation = 1:n_simulations) %>%
  mutate(index = 1:n()) %>% 
  group_by(index, n, simulation) %>% 
  mutate(data = list(tibble(group1 = rnorm(n = n,
                                           mean = mean1,
                                           sd = sd1),
                            group2 = rnorm(n = n,
                                           mean = mean2,
                                           sd = sd2)) %>% 
                       pivot_longer(cols = everything()))) %>% 
  group_by(index, n, simulation) %>% 
  mutate(p.value = map_dbl(data, ~ func_permutations(df = .,
                                                     n_permutations = n_permutations,
                                                     difference = difference)),
         p.value = p.value/n_permutations) %>% 
  group_by(n) %>% 
  summarize(power = sum(p.value < 0.05) / n())

# visualize results
ggplot(data = df.power2, 
       mapping = aes(x = n,
                     y = power)) +
  geom_hline(yintercept = seq(0, 1, 0.1),
             linetype = 2,
             color = "gray50",
             size = 0.1) + 
  geom_smooth(method = "loess",
              color = "black") +
  geom_point(shape = 21)
```

# difference in significance vs. significant differences 

```{r}
set.seed(2) # make reproducible
n = 10
mean1 = 0
sd1 = 0.3
mean2 = 0.5
sd2 = 0.4
mean3 = 0.2
sd3 = 0.4

# simulate data 
df.difference = tibble(placebo = rnorm(n = n,
                                       mean = mean1,
                                       sd = sd1),
                       group_1 = rnorm(n = n,
                                       mean = mean2, 
                                       sd = sd2),
                       group_2 = rnorm(n = n,
                                       mean = mean3,
                                       sd = sd3)) %>% 
  pivot_longer(cols = everything(),
               names_to = "group",
               values_to = "outcome") %>% 
  mutate(group = factor(group, levels = c("placebo", "group_1", "group_2")))

# visualize results 
ggplot(data = df.difference,
       mapping = aes(x = group,
                     y = outcome)) +
  stat_summary(fun.data = "mean_cl_normal") + 
  geom_signif(comparisons = list(c("placebo", "group_1")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1) + 
  geom_signif(comparisons = list(c("placebo", "group_2")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1.4) + 
  geom_signif(comparisons = list(c("group_1", "group_2")),
              map_signif_level = T,
              textsize = 6,
              y_position = 1.2) + 
  scale_x_discrete(labels = c("Placebo", "Treatment A", "Treatment B")) +
  coord_cartesian(ylim = c(-0.2, 1.5))

# placebo vs. group_1
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("placebo", "group_1")))

# placebo vs. group_2
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("placebo", "group_2")))

# group_1 vs. group_2
t.test(formula = outcome ~ group,
       data = df.difference %>% 
         filter(group %in% c("group_1", "group_2")))
```

# when to standardize predictors 

## read in data set 

```{r}
df.poker = read_csv("data/poker.csv") %>% 
  # mutate(skill = 3 - skill,
  mutate(skill_fct = factor(skill,
                        # levels = 1:2,
                        levels = 2:1,
                        labels = c("average", "expert")),
         hand_fct = factor(hand,
                       levels = 1:3,
                       labels = c("bad", "neutral", "good")),
         skill_z = scale(skill),
         hand_z = scale(hand),
         skill_c = scale(skill, scale = F),
         hand_c = scale(hand, scale = F))
```

## visualize results 

```{r}
df.plot = df.poker

p = ggplot(data = df.plot,
       mapping = aes(x = hand_fct,
                     y = balance,
                     group = skill_fct,
                     color = skill_fct,
                     fill = skill_fct)) + 
  geom_point(alpha = 0.2,
             position = position_jitterdodge(dodge.width = 0.5,
                                             jitter.width = 0.1),
             show.legend = F) + 
  stat_summary(fun.data = "mean_cl_boot",
               position = position_dodge(width = 0.5),
               size = 1,
               color = "black",
               shape = 21) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(x = "hand",
       fill = "skill") +
  theme(legend.position = "bottom")
p 
```

## data table 

```{r}
df.poker %>% 
  select(hand, skill, hand_fct, skill_fct, balance) %>% 
  sample_n(7) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## continuous predictors (not normalized)

```{r}
# with continuous predictor 
fit1 = lm(formula = balance ~ 1 + hand + skill, 
   data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand * skill, 
   data = df.poker)
summary(fit2)
```

## correlations between predictors 

```{r}
df.poker %>% 
  select(hand, skill, balance) %>% 
  mutate(hand_x_skill = hand * skill) %>% 
  select(hand, skill, hand_x_skill, balance) %>% 
  sample_n(4) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```



```{r}
df.poker %>% 
  mutate(hand_x_skill = hand * skill) %>% 
  select(hand, skill, hand_x_skill, balance) %>% 
  correlate() %>% 
  shave() %>% 
  fashion() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## with continuous predictors (centered)

```{r}
fit1 = lm(formula = balance ~ 1 + hand_c + skill_c, 
   data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_c * skill_c, 
   data = df.poker)
summary(fit2)
```

```{r}
df.poker %>% 
  mutate(hand_x_skill_c = hand_c * skill_c) %>% 
  select(hand_c, skill_c, hand_x_skill_c, balance) %>% 
  correlate() %>% 
  shave() %>% 
  fashion() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```



# dummy-coding vs. effect coding 

## model fits 

```{r}
# df.poker = df.poker %>% 
#   mutate(hand = hand_fct)

fit1 = lm(formula = balance ~ 1 + hand, 
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand, 
          contrasts = list(hand = "contr.sum"),
          data = df.poker)
summary(fit2)
```

## coefficients

```{r}
# dummy coded 
fit1 %>% 
  tidy() %>% 
  select(term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)

# effect coded 
fit2 %>% 
  tidy() %>% 
  select(term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  kable(digits = 2) %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```


## model matrix: dummy coding

```{r}
model.matrix( ~ hand, 
              data = df.poker %>% 
                distinct(hand),
              contrasts = list(hand = "contr.treatment")) %>% 
  as_tibble() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## model matrix: effect coding

```{r}
model.matrix( ~ hand, 
              data = df.poker %>% 
                distinct(hand),
              contrasts = list(hand = "contr.sum")) %>% 
  as_tibble() %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

```{r}
df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = round(mean(balance), 2)) %>% 
  kable() %>% 
  kable_styling(bootstrap_options = "striped",
              full_width = F)
```

## categorical predictors (effect-coded)

```{r}
fit1 = lm(formula = balance ~ 1 + skill_fct,
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + skill_fct, 
          contrasts = list(skill_fct = "contr.sum"),
          data = df.poker)
summary(fit2)

contr.sum(2)
contr.treatment(2)
```

```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct,
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_fct, 
          contrasts = list(hand_fct = "contr.sum"),
          data = df.poker)
summary(fit2)

model.matrix( ~ hand_fct, 
              data = df.poker %>% 
                distinct(hand_fct),
              contrasts = list(hand_fct = "contr.sum"))
```

```{r}
model.matrix( ~ hand_fct + skill_fct, 
              data = df.poker %>% 
                distinct(hand_fct, skill_fct),
              contrasts = list(hand_fct = "contr.sum",
                               skill_fct = "contr.sum"))
```

```{r}
9.7715 - 3.8300
9.7715 + 0.5751
9.7715 + (-3.8300) * -1 + 0.5751 * -1
```


```{r}
df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))
```

```{r}
params = fit2 %>% 
  tidy() %>% 
  pull(estimate)

params[1] + (1) * params[2] + (0) * params[3]
params[1] + (0) * params[2] + (1) * params[3]
params[1] + (-1) * params[2] + (-1) * params[3]
```

```{r}
group_means = df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))

(group_means$mean[3] - group_means$mean[1]) / 2
```




```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct + skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)
summary(fit1)

fit2 = lm(formula = balance ~ 1 + hand_fct * skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)
summary(fit2)
```

```{r}
df.poker %>% 
  group_by(hand, skill) %>% 
  summarize(mean = mean(balance))
```



```{r}
# df.model = fit1 %>%
df.model = fit2 %>%
  augment() %>% 
  distinct(hand_fct, skill_fct, balance = .fitted)
  
p + 
  geom_point(data = df.model,
             color = "black",
             position = position_dodge(width = 0.5),
             size = 3)
```


- Given the dummy coding, the intercept represents the mean for `hand = bad` in the model without the interaction, but it represents the mean for `hand = bad, skill = average` in the model with the intercept 

```{r}
df.poker %>% 
  group_by(hand, skill) %>% 
  summarize(mean = mean(balance))

df.poker %>% 
  group_by(hand) %>% 
  summarize(mean = mean(balance))

df.poker %>% 
  group_by(skill) %>% 
  summarize(mean = mean(balance))

# 10.1 - 9.4
```


- Note: The outcome here should not be interpreted to mean that the quality of the hand makes no difference. 
- these are not main effects but simple effects 

```{r}
fit1 = lm(formula = balance ~ 1 + hand_fct * skill_fct, 
          contrasts = list(hand_fct = "contr.sum",
                           skill_fct = "contr.sum"),
          data = df.poker)

fit2 = lm(formula = balance ~ 1 + hand_fct * skill_fct,
          data = df.poker)

```

