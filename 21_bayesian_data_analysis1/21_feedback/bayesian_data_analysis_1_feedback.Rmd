---
title: "21 Bayesian data analysis 1"
author: "Tobias Gerstenberg"
date: "3/4/2019"
output: 
  html_document:
    toc: true
    toc_depth: 4
    theme: cosmo
    highlight: tango
---

```{r setup, include=FALSE}
library("knitr")
library("DT")
library("tidyverse")
opts_chunk$set(echo = TRUE)
theme_set(
  theme_classic() + 
    theme(
      text = element_text(size = 20),
      panel.grid.major.y = element_line(color = "gray90")
    ) 
)
```

## Student feedback 

> The mixed model homework questions were too easy. It would be great to have more practice for the Bayesian portion of the homework.

> Cool hearing about your work and the interactive part was helpful. Still need a little more scaffolding on how it relates to Bayesian, though.

```{r echo=FALSE, message=FALSE}
read_csv("what-did-you-like-about-21.csv") %>% 
  set_names(c("response", "date")) %>% 
  select(response) %>% 
  datatable()
```

## What to do next time

- make the connections between Bayesian data analysis and Bayesian cognitive modeling more clear 
- make the mixed model homework more comprehensive
- comment from Andrew: "one of the important things to understand about the logit transform is that because independent probabilities multiply, and logs turn multiplication and addition, that's the 'only' way in some sense that you could have an additive model say something about probability. So it's not just about matching the domain of the function, but also matching the relationships within that domain. "